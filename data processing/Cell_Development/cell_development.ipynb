{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Workflow: From Single-Cell Data to ML-Ready Graph Input\n",
    "\n",
    "This notebook integrates several scripts to perform a full data processing pipeline. The goal is to convert raw single-cell RNA-seq data (`.h5ad`) into a set of files suitable for training a temporal graph network. The process involves:\n",
    "1.  **Setup & Configuration**: Defining all paths and importing libraries.\n",
    "2.  **Node Feature Extraction**: Identifying highly variable genes (HVGs) and extracting their expression values for each cell to serve as node features.\n",
    "3.  **Edge Inference with Palantir**: Calculating a transition probability matrix between cells to infer directed edges and their weights.\n",
    "4.  **Edge Filtering and Analysis**: Analyzing the distribution of edge weights and filtering them to retain only the most significant connections.\n",
    "5.  **Final ML Data Preparation**: Assembling the filtered edges, node labels (cell types), and timestamps into a final CSV file and a corresponding feature matrix (`.npy`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Configuration\n",
    "\n",
    "**Goal**: Import all necessary libraries and define all input/output paths in a centralized location. This makes the notebook easier to configure and maintain.\n",
    "\n",
    "**Input**: The required h5ad-related data files can be obtained through the **data_preparation.ipynb** file.\n",
    "\n",
    "**Output**: Python variables pointing to file paths and created output directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T08:08:53.649892200Z",
     "start_time": "2025-09-10T08:08:33.352433100Z"
    }
   },
   "outputs": [],
   "source": [
    "# === Library Imports ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import pickle\n",
    "from palantir.utils import run_diffusion_maps, determine_multiscale_space, compute_kernel\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# === Input Data Paths ===\n",
    "BASE_INPUT_DIR = \"./data/human_bone/\"\n",
    "H5AD_PATH = os.path.join(BASE_INPUT_DIR, \"HumanBone.h5ad\")\n",
    "CELL_MAP_PATH = os.path.join(BASE_INPUT_DIR, \"cell_map.csv\")\n",
    "CELLTYPE_MAP_PATH = os.path.join(BASE_INPUT_DIR, \"celltype_map.csv\")\n",
    "\n",
    "# === Output Directory Configuration ===\n",
    "BASE_OUTPUT_DIR = \"./result/human_bone/\"\n",
    "INTERIM_DATA_DIR = os.path.join(BASE_OUTPUT_DIR, \"interim_data\")\n",
    "ML_DATA_DIR = os.path.join(BASE_OUTPUT_DIR, \"ml_data\")\n",
    "METADATA_DIR = os.path.join(BASE_OUTPUT_DIR, \"metadata\")\n",
    "\n",
    "# --- Create output directories if they don't exist ---\n",
    "os.makedirs(INTERIM_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(ML_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(METADATA_DIR, exist_ok=True)\n",
    "\n",
    "# === Output File Paths ===\n",
    "# Metadata files\n",
    "HVG_INDEX_PATH = os.path.join(METADATA_DIR, 'HVG_1000_gene_index.csv')\n",
    "\n",
    "# Interim data files\n",
    "FULL_EDGES_PATH = os.path.join(INTERIM_DATA_DIR, 'palantir_full_edges.csv')\n",
    "FILTERED_EDGES_PATH = os.path.join(INTERIM_DATA_DIR, 'palantir_filtered_edges_gt0.1.csv')\n",
    "\n",
    "# Final ML data files\n",
    "NODE_FEATURES_PATH = os.path.join(ML_DATA_DIR, 'HumanBone_node_features_1000.pkl')\n",
    "ML_DATAFRAME_PATH = os.path.join(ML_DATA_DIR, 'ml_HumanBone.csv')\n",
    "ML_EDGE_FEATURES_PATH = os.path.join(ML_DATA_DIR, 'ml_HumanBone_edge_features.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Node Feature Extraction\n",
    "\n",
    "**Goal**: Generate feature vectors for each cell (node) based on gene expression. We select the top 1000 highly variable genes (HVGs) to create a meaningful and compact feature representation.\n",
    "\n",
    "**Input**: \n",
    "- `HumanBone.h5ad`: The main AnnData object containing the gene expression matrix.\n",
    "- `cell_map.csv`: A mapping from cell names to unique integer IDs.\n",
    "\n",
    "**Output**:\n",
    "- `HVG_1000_gene_index.csv`: A table mapping HVG gene IDs to their index in the feature vector.\n",
    "- `HumanBone_node_features_1000.pkl`: A pickled dictionary where keys are cell IDs and values are their corresponding HVG expression vectors, grouped by timepoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T08:11:07.784718900Z",
     "start_time": "2025-09-10T08:10:39.958238500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HVG index table saved to: /home/share/huadjyin/home/s_qinhua2/02code/guozhihan/DynPertub/data_code/cell_development/result/metadata/HVG_1000_gene_index.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene_ID</th>\n",
       "      <th>Gene_Symbol</th>\n",
       "      <th>HVG_Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000231749</td>\n",
       "      <td>ABCA9-AS1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000138075</td>\n",
       "      <td>ABCG5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000143921</td>\n",
       "      <td>ABCG8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000237741</td>\n",
       "      <td>AC002368.1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000254239</td>\n",
       "      <td>AC002428.2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Gene_ID Gene_Symbol  HVG_Index\n",
       "0  ENSG00000231749   ABCA9-AS1          0\n",
       "1  ENSG00000138075       ABCG5          1\n",
       "2  ENSG00000143921       ABCG8          2\n",
       "3  ENSG00000237741  AC002368.1          3\n",
       "4  ENSG00000254239  AC002428.2          4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942a80990b974306a6d510083990191d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Node Features:   0%|          | 0/88861 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Node feature data has been saved\n",
      "Total cells processed: 88861\n"
     ]
    }
   ],
   "source": [
    "# --- Load the main AnnData object ---\n",
    "adata = ad.read_h5ad(H5AD_PATH)\n",
    "\n",
    "# --- Load the cell name to integer ID mapping ---\n",
    "cell_map_df = pd.read_csv(CELL_MAP_PATH)\n",
    "cell_name_to_id = dict(zip(cell_map_df['Cell'], cell_map_df['ID']))\n",
    "\n",
    "# --- Select top 1000 highly variable genes (HVGs) ---\n",
    "# This identifies the genes with the highest variance relative to their expression level.\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=1000, flavor='cell_ranger', subset=True)\n",
    "\n",
    "# --- Save the index of the selected HVGs for reference ---\n",
    "hvg_genes = list(adata.var_names)\n",
    "gene_symbols = adata.var.loc[hvg_genes, 'gene_symbols'].values\n",
    "hvg_df = pd.DataFrame({\n",
    "    'Gene_ID': hvg_genes,\n",
    "    'Gene_Symbol': gene_symbols,\n",
    "    'HVG_Index': range(len(hvg_genes))\n",
    "})\n",
    "hvg_df.to_csv(HVG_INDEX_PATH, index=False)\n",
    "print(f\"✅ HVG index table saved to: {HVG_INDEX_PATH}\")\n",
    "display(hvg_df.head())\n",
    "\n",
    "# --- Get the expression matrix for the HVGs ---\n",
    "adata_df = pd.DataFrame(\n",
    "    adata.X.toarray() if not isinstance(adata.X, np.ndarray) else adata.X,\n",
    "    index=adata.obs_names,\n",
    "    columns=adata.var_names\n",
    ")\n",
    "\n",
    "# --- Construct the final node feature dictionary: {cell_ID: {timepoint: [expression_vector]}} ---\n",
    "expression_data = {}\n",
    "for cell_name, row in tqdm(adata.obs.iterrows(), total=adata.n_obs, desc=\"Processing Node Features\"):\n",
    "    time = row['Timepoint']\n",
    "    if pd.isna(time) or cell_name not in cell_name_to_id:\n",
    "        continue\n",
    "\n",
    "    cell_id = cell_name_to_id[cell_name]\n",
    "    expr_vector = adata_df.loc[cell_name].values.astype(float).tolist()\n",
    "    expression_data[int(cell_id)] = {int(time): expr_vector}\n",
    "\n",
    "# --- Save the feature dictionary to a .pkl file ---\n",
    "with open(NODE_FEATURES_PATH, 'wb') as f:\n",
    "    pickle.dump(expression_data, f)\n",
    "\n",
    "print(f\"\\n✅ Node feature data has been saved\")\n",
    "print(f\"Total cells processed: {len(expression_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Edge Inference with Palantir\n",
    "\n",
    "**Goal**: Infer relationships (edges) and their strengths (weights) between cells. We use the Palantir method, which involves dimensionality reduction with PCA, followed by diffusion maps to model cell-to-cell transitions.\n",
    "\n",
    "**Input**:\n",
    "- `adata` object: The AnnData object, now subsetted to include only HVGs.\n",
    "\n",
    "**Output**:\n",
    "- `palantir_full_edges.csv`: A CSV file containing all inferred edges, with columns for `source_cell`, `target_cell`, and `weight` (transition probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T08:14:46.863140900Z",
     "start_time": "2025-09-10T08:12:45.678680500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diffusion maps...\n",
      "Determining multiscale space...\n",
      "\n",
      "✅ Full edge list has been saved\n",
      "Total edges inferred: 3364346\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_cell</th>\n",
       "      <th>target_cell</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1</td>\n",
       "      <td>MantonBM3_HiSeq_5-GCGCAGTCATTCCTCG-1</td>\n",
       "      <td>0.054791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1</td>\n",
       "      <td>MantonBM8_HiSeq_2-CTACATTTCCGAATGT-1</td>\n",
       "      <td>0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1</td>\n",
       "      <td>MantonBM8_HiSeq_4-GTCAAGTAGAGAGCTC-1</td>\n",
       "      <td>0.003759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1</td>\n",
       "      <td>MantonBM4_HiSeq_4-TCTGGAACAATAGAGT-1</td>\n",
       "      <td>0.001271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1</td>\n",
       "      <td>MantonBM6_HiSeq_1-GGAGCAATCTGCGACG-1</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            source_cell                           target_cell  \\\n",
       "0  MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1  MantonBM3_HiSeq_5-GCGCAGTCATTCCTCG-1   \n",
       "1  MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1  MantonBM8_HiSeq_2-CTACATTTCCGAATGT-1   \n",
       "2  MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1  MantonBM8_HiSeq_4-GTCAAGTAGAGAGCTC-1   \n",
       "3  MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1  MantonBM4_HiSeq_4-TCTGGAACAATAGAGT-1   \n",
       "4  MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1  MantonBM6_HiSeq_1-GGAGCAATCTGCGACG-1   \n",
       "\n",
       "     weight  \n",
       "0  0.054791  \n",
       "1  0.001066  \n",
       "2  0.003759  \n",
       "3  0.001271  \n",
       "4  0.000569  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Standard single-cell preprocessing for Palantir ---\n",
    "# The data is already subset to HVGs from the previous step.\n",
    "adata_palantir = adata.copy()\n",
    "sc.pp.normalize_total(adata_palantir, target_sum=1e4) # Normalize to counts per 10,000\n",
    "sc.pp.log1p(adata_palantir) # Log-transform the data\n",
    "sc.pp.scale(adata_palantir) # Scale data to unit variance and zero mean\n",
    "sc.tl.pca(adata_palantir, n_comps=50) # Perform PCA\n",
    "\n",
    "# --- Generate diffusion maps and multiscale space ---\n",
    "# This models the probability of transitioning between cells in the PCA space.\n",
    "pca_df = pd.DataFrame(adata_palantir.obsm[\"X_pca\"], index=adata_palantir.obs_names)\n",
    "print(\"Running diffusion maps...\")\n",
    "dm_res = run_diffusion_maps(pca_df, n_components=30)\n",
    "print(\"Determining multiscale space...\")\n",
    "ms_data = determine_multiscale_space(dm_res)\n",
    "\n",
    "# --- Compute the kernel and transition probability matrix ---\n",
    "kernel = compute_kernel(ms_data, knn=30, alpha=10)\n",
    "trans_probs = kernel.multiply(1.0 / np.array(kernel.sum(axis=1)).flatten()[:, None])\n",
    "trans_probs = trans_probs.tocsr()\n",
    "\n",
    "# --- Construct the edge list DataFrame ---\n",
    "# Columns: source_cell, target_cell, weight\n",
    "rows, cols = trans_probs.nonzero()\n",
    "weights = trans_probs[rows, cols].A1\n",
    "\n",
    "cell_names = np.array(pca_df.index)\n",
    "edges_df = pd.DataFrame({\n",
    "    \"source_cell\": cell_names[rows],\n",
    "    \"target_cell\": cell_names[cols],\n",
    "    \"weight\": weights\n",
    "})\n",
    "\n",
    "# --- Save the full edge list to a CSV file ---\n",
    "edges_df.to_csv(FULL_EDGES_PATH, index=False)\n",
    "\n",
    "print(f\"\\n✅ Full edge list has been saved\")\n",
    "print(f\"Total edges inferred: {len(edges_df)}\")\n",
    "display(edges_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Edge Filtering and Analysis\n",
    "\n",
    "**Goal**: Analyze the distribution of edge weights and filter out weak connections to build a more robust graph. We will keep edges with a transition probability greater than 0.1.\n",
    "\n",
    "**Input**:\n",
    "- `palantir_full_edges.csv`: The complete list of inferred edges.\n",
    "\n",
    "**Output**:\n",
    "- `palantir_filtered_edges_gt0.1.csv`: A CSV file containing only the edges with `weight > 0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T08:15:29.224446200Z",
     "start_time": "2025-09-10T08:15:28.531067600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of edges before filtering: 3364346\n",
      "\n",
      "Number of edges above various thresholds:\n",
      "  - weight > 0.001: 3029462 edges\n",
      "  - weight > 0.005: 2049397 edges\n",
      "  - weight > 0.01: 1467918 edges\n",
      "  - weight > 0.05: 403504 edges\n",
      "  - weight > 0.1: 186044 edges\n",
      "  - weight > 0.5: 13541 edges\n",
      "\n",
      "✅ Filtered edge list (weight > 0.1) has been saved\n",
      "Number of edges after filtering: 186044\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_cell</th>\n",
       "      <th>target_cell</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1</td>\n",
       "      <td>MantonBM8_HiSeq_5-AATCGGTGTGTAATGA-1</td>\n",
       "      <td>0.108461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1</td>\n",
       "      <td>MantonBM6_HiSeq_7-TGAGCATCAAGAGTCG-1</td>\n",
       "      <td>0.227190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1</td>\n",
       "      <td>MantonBM8_HiSeq_7-GAACCTACAGGCGATA-1</td>\n",
       "      <td>0.212063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>MantonBM4_HiSeq_6-TAGAGCTTCACAGTAC-1</td>\n",
       "      <td>MantonBM1_HiSeq_3-GATCGATCAGTAAGCG-1</td>\n",
       "      <td>0.126454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>MantonBM4_HiSeq_6-TAGAGCTTCACAGTAC-1</td>\n",
       "      <td>MantonBM4_HiSeq_2-GAAACTCCATACGCTA-1</td>\n",
       "      <td>0.184523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             source_cell  \\\n",
       "23  MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1   \n",
       "35  MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1   \n",
       "39  MantonBM6_HiSeq_5-CTGAAACAGACTAAGT-1   \n",
       "41  MantonBM4_HiSeq_6-TAGAGCTTCACAGTAC-1   \n",
       "43  MantonBM4_HiSeq_6-TAGAGCTTCACAGTAC-1   \n",
       "\n",
       "                             target_cell    weight  \n",
       "23  MantonBM8_HiSeq_5-AATCGGTGTGTAATGA-1  0.108461  \n",
       "35  MantonBM6_HiSeq_7-TGAGCATCAAGAGTCG-1  0.227190  \n",
       "39  MantonBM8_HiSeq_7-GAACCTACAGGCGATA-1  0.212063  \n",
       "41  MantonBM1_HiSeq_3-GATCGATCAGTAAGCG-1  0.126454  \n",
       "43  MantonBM4_HiSeq_2-GAAACTCCATACGCTA-1  0.184523  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Analyze the distribution of edge weights ---\n",
    "thresholds = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "print(f\"Total number of edges before filtering: {len(edges_df)}\\n\")\n",
    "print(\"Number of edges above various thresholds:\")\n",
    "for t in thresholds:\n",
    "    count = (edges_df[\"weight\"] > t).sum()\n",
    "    print(f\"  - weight > {t}: {count} edges\")\n",
    "\n",
    "# --- Filter edges with weight > 0.1 ---\n",
    "FILTER_THRESHOLD = 0.1\n",
    "filtered_edges_df = edges_df[edges_df[\"weight\"] > FILTER_THRESHOLD].copy()\n",
    "\n",
    "# --- Save the filtered edge list ---\n",
    "filtered_edges_df.to_csv(FILTERED_EDGES_PATH, index=False)\n",
    "\n",
    "print(f\"\\n✅ Filtered edge list (weight > {FILTER_THRESHOLD}) has been saved\")\n",
    "print(f\"Number of edges after filtering: {len(filtered_edges_df)}\")\n",
    "display(filtered_edges_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Final ML Data Preparation\n",
    "\n",
    "**Goal**: Assemble the final machine learning-ready datasets. This involves mapping cell names to their integer IDs, assigning labels (based on source cell type) and timestamps to each edge, and ensuring the final edge list and edge feature matrix are perfectly aligned.\n",
    "\n",
    "**Input**:\n",
    "- `palantir_filtered_edges_gt0.1.csv`: The filtered list of cell-to-cell connections.\n",
    "- `HumanBone.h5ad`: Used to retrieve `Celltype` and `Timepoint` metadata for each cell.\n",
    "- `cell_map.csv`: Mapping from cell names to integer IDs.\n",
    "- `celltype_map.csv`: Mapping from cell type names to integer labels.\n",
    "\n",
    "**Output**:\n",
    "- `ml_HumanBone.csv`: The final edge data, with columns `u`, `i`, `ts`, `label`, and `idx`.\n",
    "- `ml_HumanBone_edge_features.npy`: A NumPy array where each row corresponds to an edge in the CSV file and contains its weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T08:16:30.267642800Z",
     "start_time": "2025-09-10T08:16:26.262492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final ML DataFrame saved to: /home/share/huadjyin/home/s_qinhua2/02code/guozhihan/DynPertub/data_code/cell_development/result/ml_data/ml_HumanBone.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "      <th>ts</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44953</td>\n",
       "      <td>48932</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47645</td>\n",
       "      <td>46539</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47646</td>\n",
       "      <td>43921</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47648</td>\n",
       "      <td>43198</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47649</td>\n",
       "      <td>43267</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       u      i  ts  label  idx\n",
       "0  44953  48932  19      0    1\n",
       "1  47645  46539  19      5    2\n",
       "2  47646  43921  19      5    3\n",
       "3  47648  43198  19      3    4\n",
       "4  47649  43267  19      5    5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Aligned edge features has been saved to: ml_data folder.\n",
      "\n",
      "--- Final Validation ---\n",
      "Rows in ml_HumanBone.csv: 186044\n",
      "Rows in ml_HumanBone_edge_features.npy: 186044\n",
      "\n",
      "✅ Row counts match. Data preparation successful!\n"
     ]
    }
   ],
   "source": [
    "# === Step 1: Load all necessary mapping files and metadata ===\n",
    "\n",
    "# --- Load the filtered edges we just created ---\n",
    "df = pd.read_csv(FILTERED_EDGES_PATH)\n",
    "\n",
    "# --- Load Cell -> ID mapping (already loaded, but re-assigning for clarity) ---\n",
    "cell_to_id = cell_name_to_id\n",
    "\n",
    "# --- Load AnnData to get Celltype and Timepoint metadata ---\n",
    "adata_meta = ad.read_h5ad(H5AD_PATH)\n",
    "cell_to_celltype = adata_meta.obs[\"Celltype\"].to_dict()\n",
    "cell_to_timepoint = adata_meta.obs[\"Timepoint\"].to_dict()\n",
    "\n",
    "# --- Load Celltype -> Label ID mapping ---\n",
    "celltype_mapping = pd.read_csv(CELLTYPE_MAP_PATH)\n",
    "celltype_to_id = dict(zip(celltype_mapping[\"Celltype\"], celltype_mapping[\"ID\"]))\n",
    "\n",
    "# === Step 2: Create a mapping from Cell ID -> Label ID ===\n",
    "# This is needed to assign a label to each edge based on its source node's type.\n",
    "id_to_label = {}\n",
    "for cell, celltype in cell_to_celltype.items():\n",
    "    if cell in cell_to_id and celltype in celltype_to_id:\n",
    "        id_to_label[cell_to_id[cell]] = celltype_to_id[celltype]\n",
    "\n",
    "# === Step 3: Map columns for the final DataFrame ===\n",
    "# 'u' for source, 'i' for target, 'ts' for timestamp, 'label' for source node's class.\n",
    "df[\"u\"] = df[\"source_cell\"].map(cell_to_id)\n",
    "df[\"i\"] = df[\"target_cell\"].map(cell_to_id)\n",
    "df[\"label\"] = df[\"u\"].map(id_to_label)\n",
    "df[\"ts\"] = df[\"source_cell\"].map(cell_to_timepoint)\n",
    "\n",
    "# === Step 4: Clean, sort, and index the final DataFrame ===\n",
    "df_ml = df[['u', 'i', 'ts', 'label', 'weight']].copy()\n",
    "\n",
    "# --- Store original indices before dropping NaNs to keep features aligned ---\n",
    "df_ml.dropna(inplace=True)\n",
    "valid_indices = df_ml.index\n",
    "\n",
    "# --- Sort by timestamp and reset index for the final output ---\n",
    "df_out = df_ml.sort_values(\"ts\").reset_index(drop=True)\n",
    "\n",
    "# --- Create the final event index ---\n",
    "df_out[\"idx\"] = range(1, len(df_out) + 1)\n",
    "\n",
    "# --- Extract and align edge features --- \n",
    "# This is a critical step to ensure the .npy file rows match the .csv file rows.\n",
    "edge_features = df.loc[valid_indices].sort_values(\"ts\")[['weight']].values\n",
    "\n",
    "# === Step 5: Save final CSV and NPY files ===\n",
    "\n",
    "# --- Save the final DataFrame ---\n",
    "df_to_save = df_out[['u', 'i', 'ts', 'label', 'idx']]\n",
    "df_to_save.to_csv(ML_DATAFRAME_PATH, index=False)\n",
    "print(f\"✅ Final ML DataFrame saved to: {ML_DATAFRAME_PATH}\")\n",
    "display(df_to_save.head())\n",
    "\n",
    "# --- Save the aligned edge features ---\n",
    "np.save(ML_EDGE_FEATURES_PATH, edge_features)\n",
    "print(f\"\\n✅ Aligned edge features has been saved to: ml_data folder.\")\n",
    "\n",
    "# === Step 6: Final Validation ===\n",
    "# Ensure the number of rows in the CSV and the NPY array are identical.\n",
    "df_rows = len(df_to_save)\n",
    "feat_rows = edge_features.shape[0]\n",
    "\n",
    "print(f\"\\n--- Final Validation ---\")\n",
    "print(f\"Rows in {os.path.basename(ML_DATAFRAME_PATH)}: {df_rows}\")\n",
    "print(f\"Rows in {os.path.basename(ML_EDGE_FEATURES_PATH)}: {feat_rows}\")\n",
    "\n",
    "if df_rows == feat_rows:\n",
    "    print(\"\\n✅ Row counts match. Data preparation successful!\")\n",
    "else:\n",
    "    print(\"\\n❌ ERROR: Row counts do not match. Please check the alignment logic!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
